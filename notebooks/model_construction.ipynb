{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b3fccf1-7bf0-485b-a88c-1d7908c2a641",
   "metadata": {},
   "source": [
    "# **Построение модели**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d383bfe-2cb9-4fc6-86af-447affe4395a",
   "metadata": {},
   "source": [
    "В качестве baseline модели для решения задачи классификации мы используем `Logistic regression`. После чего попробуем использовать `KNN`, `Random forest`, `GBM` из библиотеки `xgboost`. Подберем гипперпараметры для данных моделей. Также сделаем отбор признаков в датасете, посмотрим как улучшится качество. Также можно выделить признаки с помощью `PCA`. Будем пытаться улучшить модели по метрике `AUC-ROC`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ff9f28d-c6c1-4e77-a4d2-b0110e80604b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edeb86cb-fee1-40f0-949d-d80278974187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Annual_Income</th>\n",
       "      <th>Monthly_Inhand_Salary</th>\n",
       "      <th>Num_Bank_Accounts</th>\n",
       "      <th>Num_Credit_Card</th>\n",
       "      <th>Interest_Rate</th>\n",
       "      <th>Num_of_Loan</th>\n",
       "      <th>Delay_from_due_date</th>\n",
       "      <th>Num_of_Delayed_Payment</th>\n",
       "      <th>...</th>\n",
       "      <th>Credit_Mix</th>\n",
       "      <th>Outstanding_Debt</th>\n",
       "      <th>Credit_Utilization_Ratio</th>\n",
       "      <th>Credit_History_Age</th>\n",
       "      <th>Payment_of_Min_Amount</th>\n",
       "      <th>Total_EMI_per_month</th>\n",
       "      <th>Amount_invested_monthly</th>\n",
       "      <th>Payment_Behaviour</th>\n",
       "      <th>Monthly_Balance</th>\n",
       "      <th>Credit_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.0</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>1824.843333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>_</td>\n",
       "      <td>809.98</td>\n",
       "      <td>26.822620</td>\n",
       "      <td>265.0000</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>80.415295</td>\n",
       "      <td>High_spent_Small_value_payments</td>\n",
       "      <td>312.494089</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.0</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>4194.150202</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>30.9254</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>809.98</td>\n",
       "      <td>31.944960</td>\n",
       "      <td>221.1933</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>118.280222</td>\n",
       "      <td>Low_spent_Large_value_payments</td>\n",
       "      <td>284.629162</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.0</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>4194.150202</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>809.98</td>\n",
       "      <td>28.609352</td>\n",
       "      <td>267.0000</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>81.699521</td>\n",
       "      <td>Low_spent_Medium_value_payments</td>\n",
       "      <td>331.209863</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.0</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>4194.150202</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>809.98</td>\n",
       "      <td>31.377862</td>\n",
       "      <td>268.0000</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>199.458074</td>\n",
       "      <td>Low_spent_Small_value_payments</td>\n",
       "      <td>223.451310</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.0</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>1824.843333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>30.9254</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>809.98</td>\n",
       "      <td>24.797347</td>\n",
       "      <td>269.0000</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>41.420153</td>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "      <td>341.489231</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age Occupation  Annual_Income  Monthly_Inhand_Salary  Num_Bank_Accounts  \\\n",
       "0  23.0  Scientist       19114.12            1824.843333                3.0   \n",
       "1  23.0  Scientist       19114.12            4194.150202                3.0   \n",
       "2  33.0  Scientist       19114.12            4194.150202                3.0   \n",
       "3  23.0  Scientist       19114.12            4194.150202                3.0   \n",
       "4  23.0  Scientist       19114.12            1824.843333                3.0   \n",
       "\n",
       "   Num_Credit_Card  Interest_Rate  Num_of_Loan  Delay_from_due_date  \\\n",
       "0              4.0            3.0          4.0                  3.0   \n",
       "1              4.0            3.0          4.0                 -1.0   \n",
       "2              4.0            3.0          4.0                  3.0   \n",
       "3              4.0            3.0          4.0                  5.0   \n",
       "4              4.0            3.0          4.0                  6.0   \n",
       "\n",
       "   Num_of_Delayed_Payment  ...  Credit_Mix  Outstanding_Debt  \\\n",
       "0                  7.0000  ...           _            809.98   \n",
       "1                 30.9254  ...        Good            809.98   \n",
       "2                  7.0000  ...        Good            809.98   \n",
       "3                  4.0000  ...        Good            809.98   \n",
       "4                 30.9254  ...        Good            809.98   \n",
       "\n",
       "  Credit_Utilization_Ratio  Credit_History_Age  Payment_of_Min_Amount  \\\n",
       "0                26.822620            265.0000                     No   \n",
       "1                31.944960            221.1933                     No   \n",
       "2                28.609352            267.0000                     No   \n",
       "3                31.377862            268.0000                     No   \n",
       "4                24.797347            269.0000                     No   \n",
       "\n",
       "   Total_EMI_per_month Amount_invested_monthly  \\\n",
       "0            49.574949               80.415295   \n",
       "1            49.574949              118.280222   \n",
       "2            49.574949               81.699521   \n",
       "3            49.574949              199.458074   \n",
       "4            49.574949               41.420153   \n",
       "\n",
       "                  Payment_Behaviour  Monthly_Balance Credit_Score  \n",
       "0   High_spent_Small_value_payments       312.494089         True  \n",
       "1    Low_spent_Large_value_payments       284.629162         True  \n",
       "2   Low_spent_Medium_value_payments       331.209863         True  \n",
       "3    Low_spent_Small_value_payments       223.451310         True  \n",
       "4  High_spent_Medium_value_payments       341.489231         True  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_score_df = pd.read_csv(\"~/Documents/datasets/transformed_credit_score.csv\")\n",
    "\n",
    "credit_score_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9091e5f5-d75d-4174-a71a-92a4b943c0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Выделим целевую переменную \n",
    "X = credit_score_df.drop(columns = ['Credit_Score'])\n",
    "y = credit_score_df['Credit_Score']\n",
    "\n",
    "X = pd.get_dummies(X, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1642890f-8d45-41de-aa46-7b871d0f6792",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Разделим выборку на обучающую и тестовую\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify=y,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2c06e4b-1344-4c93-bb92-60d46cca99fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((79992, 43), (19999, 43))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e570e97-3106-43de-a599-850b78321ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Нормализуем данные с помощью StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "X_train_std = scaler.transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20205db2-05ee-4247-93ba-fd68e90c5025",
   "metadata": {},
   "source": [
    "Построим `baseline` в виде `LogisticRegression`, подберём гипперпараметры, затем будем пытаться улучшить рекорд  с помощью других моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99e9cba1-4515-4785-934b-be9ca8620549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC ROC score for logistic regression on train: 0.66\n",
      "F1 score for logistic regression on train: 0.84\n",
      "\n",
      "AUC ROC score for logistic regression on test: 0.66\n",
      "F1 score for logistic regression on test: 0.84\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, classification_report, f1_score\n",
    "\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "logistic_model.fit(X_train_std, y_train)\n",
    "\n",
    "print(f\"AUC ROC score for logistic regression on train: {roc_auc_score(y_train, logistic_model.predict(X_train_std)):.2f}\")\n",
    "print(f\"F1 score for logistic regression on train: {f1_score(y_train, logistic_model.predict(X_train_std)):.2f}\\n\")\n",
    "print(f\"AUC ROC score for logistic regression on test: {roc_auc_score(y_test, logistic_model.predict(X_test_std)):.2f}\")\n",
    "print(f\"F1 score for logistic regression on test: {f1_score(y_test, logistic_model.predict(X_test_std)):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5463d9df-6c91-476b-9a9f-13aabb805b39",
   "metadata": {},
   "source": [
    "Подберем гипперпараметры с помощью `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f05fa656-8d3d-4b60-ab98-3e7547e11e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best Score: 0.7845980203143406\n",
      "Test Score: 0.7848790104208406\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear', 'lbfgs']\n",
    "}\n",
    "\n",
    "grid_search1 = GridSearchCV(estimator=logistic_model, param_grid=param_grid, cv=5, scoring='roc_auc')\n",
    "\n",
    "grid_search1.fit(X_train_std, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search1.best_params_)\n",
    "print(\"Best Score:\", grid_search1.best_score_)\n",
    "print(\"Test Score:\", grid_search1.score(X_test_std, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ba3945-0c0d-4f24-8f8c-e1fc6cc302b5",
   "metadata": {},
   "source": [
    "Подберем гипперпараметры более масштабно с помощью `RandomizedSearch`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933c2dbc-0854-43b9-b8e4-7ef07edec502",
   "metadata": {},
   "source": [
    "Метрики практически не изменились, зафиксируем лучшие параметры для `LogisticRegression`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "378d1ecf-3775-4dff-b404-fe4e4511b998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC ROC score for logistic regression on test: 0.66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.64      0.41      0.50      5800\n",
      "        True       0.79      0.91      0.84     14199\n",
      "\n",
      "    accuracy                           0.76     19999\n",
      "   macro avg       0.71      0.66      0.67     19999\n",
      "weighted avg       0.75      0.76      0.74     19999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, classification_report, f1_score\n",
    "\n",
    "best_logistic_model = LogisticRegression(C = 0.1, penalty = 'l1', solver = 'liblinear')\n",
    "\n",
    "best_logistic_model.fit(X_train_std, y_train)\n",
    "\n",
    "print(f\"AUC ROC score for logistic regression on test: {roc_auc_score(y_test, best_logistic_model.predict(X_test_std)):.2f}\")\n",
    "print(classification_report(y_test, best_logistic_model.predict(X_test_std)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e50eb26c-8c31-476e-b79e-57b3940d4fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средний AUC ROC с использованием кросс-валидации: 0.7843576776831229\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "pipeline = make_pipeline(StandardScaler(), LogisticRegression(C=0.1, penalty='l1', solver='liblinear'))\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(pipeline, X, y, cv=kf, scoring='roc_auc')\n",
    "\n",
    "print(\"Mean AUC-ROC with cross validation on logistic regression:\", np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8262a5-c792-4ad0-9d3f-32e4445161fc",
   "metadata": {},
   "source": [
    "Теперь обучим модель `RandomForestClassifier`, подберем гипперпараметры и посмотрим как улучшится `AUC_ROC`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7492de6a-b70b-41e9-b6e9-54eed30e6776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC ROC score for random forest on test: 0.84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.79      0.76      0.78      5800\n",
      "        True       0.90      0.92      0.91     14199\n",
      "\n",
      "    accuracy                           0.87     19999\n",
      "   macro avg       0.85      0.84      0.84     19999\n",
      "weighted avg       0.87      0.87      0.87     19999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "rf_model.fit(X_train_std, y_train)\n",
    "\n",
    "print(f\"AUC ROC score for random forest on test: {roc_auc_score(y_test, rf_model.predict(X_test_std)):.2f}\")\n",
    "print(classification_report(y_test, rf_model.predict(X_test_std)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "26b5c3d7-b770-4c03-a2e8-06f9dabe3b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "[CV 1/3] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 2/3] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 3/3] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 1/3] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.869 total time=  10.9s\n",
      "[CV 2/3] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.870 total time=  11.0s\n",
      "[CV 3/3] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.872 total time=  10.1s\n",
      "[CV 1/3] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.912 total time=  19.8s\n",
      "[CV 2/3] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.916 total time=  19.5s\n",
      "[CV 3/3] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.915 total time=  19.4s\n",
      "[CV 1/3] END max_depth=5, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.837 total time=   1.6s\n",
      "[CV 2/3] END max_depth=5, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.842 total time=   1.7s\n",
      "[CV 3/3] END max_depth=5, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.841 total time=   1.6s\n",
      "[CV 1/3] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.904 total time=  17.7s\n",
      "[CV 2/3] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.906 total time=  17.6s\n",
      "[CV 3/3] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.906 total time=  17.7s\n",
      "[CV 1/3] END max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/3] END max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/3] END max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/3] END max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.908 total time=   9.5s\n",
      "[CV 2/3] END max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.909 total time=   9.4s\n",
      "[CV 3/3] END max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.911 total time=   9.6s\n",
      "[CV 1/3] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.902 total time=  17.2s\n",
      "[CV 2/3] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.905 total time=  16.9s\n",
      "[CV 3/3] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.905 total time=  17.2s\n",
      "[CV 1/3] END max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/3] END max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/3] END max_depth=30, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/3] END max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.836 total time=   3.1s\n",
      "[CV 2/3] END max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.839 total time=   3.0s\n",
      "[CV 3/3] END max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.843 total time=   3.0s\n",
      "[CV 1/3] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.903 total time=  17.4s\n",
      "[CV 2/3] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.906 total time=  17.0s\n",
      "[CV 3/3] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.906 total time=  17.4s\n",
      "[CV 1/3] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.902 total time=   9.2s\n",
      "[CV 2/3] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.904 total time=   8.8s\n",
      "[CV 3/3] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.904 total time=   9.1s\n",
      "[CV 1/3] END max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/3] END max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/3] END max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/3] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.904 total time=   5.5s\n",
      "[CV 2/3] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.908 total time=   5.5s\n",
      "[CV 3/3] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.907 total time=   5.4s\n",
      "[CV 1/3] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/3] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/3] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/3] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.906 total time=   4.9s\n",
      "[CV 2/3] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.910 total time=   4.9s\n",
      "[CV 3/3] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.908 total time=   5.0s\n",
      "[CV 1/3] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.841 total time=   1.8s\n",
      "[CV 2/3] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.842 total time=   1.8s\n",
      "[CV 3/3] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.845 total time=   1.8s\n",
      "[CV 1/3] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/3] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/3] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/3] END max_depth=50, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 2/3] END max_depth=50, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 3/3] END max_depth=50, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=nan total time=   0.0s\n",
      "[CV 1/3] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/3] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/3] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/3] END max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.911 total time=  22.2s\n",
      "[CV 2/3] END max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.914 total time=  21.4s\n",
      "[CV 3/3] END max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.914 total time=  21.9s\n",
      "[CV 1/3] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.870 total time=   6.2s\n",
      "[CV 2/3] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.871 total time=   6.0s\n",
      "[CV 3/3] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.873 total time=   6.0s\n",
      "[CV 1/3] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.901 total time=   5.1s\n",
      "[CV 2/3] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.904 total time=   5.0s\n",
      "[CV 3/3] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.903 total time=   5.0s\n",
      "[CV 1/3] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.844 total time=   1.8s\n",
      "[CV 2/3] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.845 total time=   1.8s\n",
      "[CV 3/3] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.847 total time=   1.8s\n",
      "[CV 1/3] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.842 total time=   3.4s\n",
      "[CV 2/3] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.842 total time=   3.5s\n",
      "[CV 3/3] END max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.846 total time=   3.4s\n",
      "[CV 1/3] END max_depth=50, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/3] END max_depth=50, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/3] END max_depth=50, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/3] END max_depth=50, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/3] END max_depth=50, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/3] END max_depth=50, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/3] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/3] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/3] END max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/3] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.898 total time=  16.2s\n",
      "[CV 2/3] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.900 total time=  16.3s\n",
      "[CV 3/3] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.900 total time=  16.4s\n",
      "[CV 1/3] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.905 total time=  20.5s\n",
      "[CV 2/3] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.908 total time=  20.2s\n",
      "[CV 3/3] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.908 total time=  19.8s\n",
      "Best Parameters: {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 30}\n",
      "Best Score: 0.9142972287130652\n",
      "Test Score: 0.928113338481826\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 200], \n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth': [5, 10, 20, 30, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rand_search1 = RandomizedSearchCV(estimator=rf_model, \n",
    "                                  param_distributions=param_dist, \n",
    "                                  cv=3,\n",
    "                                  n_iter=30,\n",
    "                                  scoring='roc_auc', \n",
    "                                  verbose = 3)\n",
    "\n",
    "rand_search1.fit(X_train_std, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", rand_search1.best_params_)\n",
    "print(\"Best Score:\", rand_search1.best_score_)\n",
    "print(\"Test Score:\", rand_search1.score(X_test_std, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4cd9cca0-a42e-48c9-a520-76db0d162eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC ROC score for best random forest on test: 0.84\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.80      0.75      0.77      5800\n",
      "        True       0.90      0.92      0.91     14199\n",
      "\n",
      "    accuracy                           0.87     19999\n",
      "   macro avg       0.85      0.84      0.84     19999\n",
      "weighted avg       0.87      0.87      0.87     19999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_rf_model = RandomForestClassifier(n_estimators = 200, \n",
    "                                       min_samples_split = 2, \n",
    "                                       min_samples_leaf = 1, \n",
    "                                       max_features = 'log2', \n",
    "                                       max_depth = 30)\n",
    "\n",
    "best_rf_model.fit(X_train_std, y_train)\n",
    "\n",
    "print(f\"AUC ROC score for best random forest on test: {roc_auc_score(y_test, best_rf_model.predict(X_test_std)):.2f}\")\n",
    "print(\"Classification report:\\n\", classification_report(y_test, best_rf_model.predict(X_test_std)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3c6eca6f-52f7-4f84-b718-99446bfec0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUC-ROC with cross validation on fandom forest: 0.9261324394787753\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "pipeline = make_pipeline(StandardScaler(), RandomForestClassifier(n_estimators = 200, \n",
    "                                       min_samples_split = 2, \n",
    "                                       min_samples_leaf = 1, \n",
    "                                       max_features = 'log2', \n",
    "                                       max_depth = 30))\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(pipeline, X, y, cv=kf, scoring='roc_auc')\n",
    "\n",
    "print(\"Mean AUC-ROC with cross validation on fandom forest:\", np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8153ec-251a-4b96-91b7-8e7470f0f378",
   "metadata": {},
   "source": [
    "Теперь обучим модель `KNeighborsClassifier`, подберем гипперпараметры и посмотрим как улучшится `AUC_ROC`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "536f886e-2737-4bb0-acb8-77feef1835c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC ROC score for k-nearest neighbors on train: 0.77\n",
      "F1 score for k-nearest neighbors on train: 0.89\n",
      "\n",
      "AUC ROC score for k-nearest neighbors on test: 0.69\n",
      "F1 score for k-nearest neighbors on test: 0.85\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors = 5)\n",
    "\n",
    "knn_model.fit(X_train_std, y_train)\n",
    "\n",
    "print(f\"AUC ROC score for k-nearest neighbors on train: {roc_auc_score(y_train, knn_model.predict(X_train_std)):.2f}\")\n",
    "print(f\"F1 score for k-nearest neighbors on train: {f1_score(y_train, knn_model.predict(X_train_std)):.2f}\\n\")\n",
    "print(f\"AUC ROC score for k-nearest neighbors on test: {roc_auc_score(y_test, knn_model.predict(X_test_std)):.2f}\")\n",
    "print(f\"F1 score for k-nearest neighbors on test: {f1_score(y_test, knn_model.predict(X_test_std)):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085da812-77b2-436a-be6e-1170aaa70770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=3, weights=uniform;, score=0.740 total time=   1.5s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=3, weights=uniform;, score=0.735 total time=   1.4s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=3, weights=uniform;, score=0.737 total time=   1.4s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=3, weights=uniform;, score=0.742 total time=   1.4s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=3, weights=uniform;, score=0.738 total time=   1.4s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=3, weights=distance;, score=0.746 total time=   1.6s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=3, weights=distance;, score=0.743 total time=   1.5s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=3, weights=distance;, score=0.742 total time=   1.4s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=3, weights=distance;, score=0.749 total time=   1.4s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=3, weights=distance;, score=0.745 total time=   1.4s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=5, weights=uniform;, score=0.765 total time=   1.4s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=5, weights=uniform;, score=0.760 total time=   1.4s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=5, weights=uniform;, score=0.761 total time=   1.4s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=5, weights=uniform;, score=0.768 total time=   1.4s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=5, weights=uniform;, score=0.764 total time=   1.4s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=5, weights=distance;, score=0.771 total time=   1.4s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=5, weights=distance;, score=0.767 total time=   1.4s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=5, weights=distance;, score=0.767 total time=   1.5s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=5, weights=distance;, score=0.775 total time=   1.4s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=5, weights=distance;, score=0.770 total time=   1.4s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=7, weights=uniform;, score=0.776 total time=   1.4s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=7, weights=uniform;, score=0.770 total time=   1.4s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=7, weights=uniform;, score=0.774 total time=   1.4s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=7, weights=uniform;, score=0.778 total time=   1.4s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=7, weights=uniform;, score=0.776 total time=   1.4s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.782 total time=   1.4s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.778 total time=   1.4s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.780 total time=   1.4s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.786 total time=   1.7s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.782 total time=   1.4s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.783 total time=   1.4s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.776 total time=   1.4s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.782 total time=   1.4s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.784 total time=   1.4s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.781 total time=   1.5s\n",
      "[CV 1/5] END metric=euclidean, n_neighbors=9, weights=distance;, score=0.789 total time=   1.4s\n",
      "[CV 2/5] END metric=euclidean, n_neighbors=9, weights=distance;, score=0.784 total time=   1.4s\n",
      "[CV 3/5] END metric=euclidean, n_neighbors=9, weights=distance;, score=0.787 total time=   1.7s\n",
      "[CV 4/5] END metric=euclidean, n_neighbors=9, weights=distance;, score=0.792 total time=   1.6s\n",
      "[CV 5/5] END metric=euclidean, n_neighbors=9, weights=distance;, score=0.787 total time=   1.7s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=3, weights=uniform;, score=0.764 total time=  12.2s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=3, weights=uniform;, score=0.762 total time=  12.1s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=3, weights=uniform;, score=0.762 total time=  12.3s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=3, weights=uniform;, score=0.767 total time=  12.3s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=3, weights=uniform;, score=0.766 total time=  12.2s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.772 total time=  12.3s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.771 total time=  12.3s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.770 total time=  12.1s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.777 total time=  12.0s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.775 total time=  12.7s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=5, weights=uniform;, score=0.788 total time=  12.4s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=5, weights=uniform;, score=0.787 total time=  12.1s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=5, weights=uniform;, score=0.784 total time=  12.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=5, weights=uniform;, score=0.789 total time=  12.1s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=5, weights=uniform;, score=0.788 total time=  12.1s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.797 total time=  12.4s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.796 total time=  12.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.793 total time=  12.0s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.799 total time=  12.1s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.797 total time=  12.6s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.799 total time=  12.3s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.797 total time=  12.0s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.796 total time=  12.3s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.799 total time=  12.4s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.797 total time=  12.3s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=7, weights=distance;, score=0.809 total time=  12.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=7, weights=distance;, score=0.806 total time=  12.1s\n",
      "[CV 3/5] END metric=manhattan, n_neighbors=7, weights=distance;, score=0.805 total time=  12.5s\n",
      "[CV 4/5] END metric=manhattan, n_neighbors=7, weights=distance;, score=0.809 total time=  12.3s\n",
      "[CV 5/5] END metric=manhattan, n_neighbors=7, weights=distance;, score=0.806 total time=  12.6s\n",
      "[CV 1/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.804 total time=  13.0s\n",
      "[CV 2/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.801 total time=  12.4s\n"
     ]
    }
   ],
   "source": [
    "param_dist = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "}\n",
    "\n",
    "grid_search2 = GridSearchCV(estimator=knn_model, \n",
    "                            param_grid=param_dist, \n",
    "                            cv=5, \n",
    "                            scoring='roc_auc',\n",
    "                            verbose = 3)\n",
    "\n",
    "grid_search2.fit(X_train_std, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search2.best_params_)\n",
    "print(\"Best Score:\", grid_search2.best_score_)\n",
    "print(\"Test Score:\", grid_search2.score(X_test_std, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041512da-9531-4f01-a20d-d241d301071f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
