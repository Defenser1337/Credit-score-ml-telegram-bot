{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b3fccf1-7bf0-485b-a88c-1d7908c2a641",
   "metadata": {},
   "source": [
    "# **Построение модели**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d383bfe-2cb9-4fc6-86af-447affe4395a",
   "metadata": {},
   "source": [
    "В качестве baseline модели для решения задачи классификации мы используем `Logistic regression`. После чего попробуем использовать `KNN`, `Random forest`, `GBM` из библиотеки `xgboost`. Подберем гипперпараметры для данных моделей. Также сделаем отбор признаков в датасете, посмотрим как улучшится качество. Также можно выделить признаки с помощью `PCA`. Будем пытаться улучшить модели по метрике `AUC-ROC`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ff9f28d-c6c1-4e77-a4d2-b0110e80604b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.metrics import roc_auc_score, classification_report, f1_score\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edeb86cb-fee1-40f0-949d-d80278974187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Annual_Income</th>\n",
       "      <th>Monthly_Inhand_Salary</th>\n",
       "      <th>Num_Bank_Accounts</th>\n",
       "      <th>Num_Credit_Card</th>\n",
       "      <th>Interest_Rate</th>\n",
       "      <th>Num_of_Loan</th>\n",
       "      <th>Delay_from_due_date</th>\n",
       "      <th>Num_of_Delayed_Payment</th>\n",
       "      <th>...</th>\n",
       "      <th>Credit_Mix</th>\n",
       "      <th>Outstanding_Debt</th>\n",
       "      <th>Credit_Utilization_Ratio</th>\n",
       "      <th>Credit_History_Age</th>\n",
       "      <th>Payment_of_Min_Amount</th>\n",
       "      <th>Total_EMI_per_month</th>\n",
       "      <th>Amount_invested_monthly</th>\n",
       "      <th>Payment_Behaviour</th>\n",
       "      <th>Monthly_Balance</th>\n",
       "      <th>Credit_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.0</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>1824.843333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>_</td>\n",
       "      <td>809.98</td>\n",
       "      <td>26.822620</td>\n",
       "      <td>265.0000</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>80.415295</td>\n",
       "      <td>High_spent_Small_value_payments</td>\n",
       "      <td>312.494089</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.0</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>4194.150202</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>30.9254</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>809.98</td>\n",
       "      <td>31.944960</td>\n",
       "      <td>221.1933</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>118.280222</td>\n",
       "      <td>Low_spent_Large_value_payments</td>\n",
       "      <td>284.629162</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.0</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>4194.150202</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>809.98</td>\n",
       "      <td>28.609352</td>\n",
       "      <td>267.0000</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>81.699521</td>\n",
       "      <td>Low_spent_Medium_value_payments</td>\n",
       "      <td>331.209863</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.0</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>4194.150202</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>809.98</td>\n",
       "      <td>31.377862</td>\n",
       "      <td>268.0000</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>199.458074</td>\n",
       "      <td>Low_spent_Small_value_payments</td>\n",
       "      <td>223.451310</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.0</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>1824.843333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>30.9254</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>809.98</td>\n",
       "      <td>24.797347</td>\n",
       "      <td>269.0000</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>41.420153</td>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "      <td>341.489231</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age Occupation  Annual_Income  Monthly_Inhand_Salary  Num_Bank_Accounts  \\\n",
       "0  23.0  Scientist       19114.12            1824.843333                3.0   \n",
       "1  23.0  Scientist       19114.12            4194.150202                3.0   \n",
       "2  33.0  Scientist       19114.12            4194.150202                3.0   \n",
       "3  23.0  Scientist       19114.12            4194.150202                3.0   \n",
       "4  23.0  Scientist       19114.12            1824.843333                3.0   \n",
       "\n",
       "   Num_Credit_Card  Interest_Rate  Num_of_Loan  Delay_from_due_date  \\\n",
       "0              4.0            3.0          4.0                  3.0   \n",
       "1              4.0            3.0          4.0                 -1.0   \n",
       "2              4.0            3.0          4.0                  3.0   \n",
       "3              4.0            3.0          4.0                  5.0   \n",
       "4              4.0            3.0          4.0                  6.0   \n",
       "\n",
       "   Num_of_Delayed_Payment  ...  Credit_Mix  Outstanding_Debt  \\\n",
       "0                  7.0000  ...           _            809.98   \n",
       "1                 30.9254  ...        Good            809.98   \n",
       "2                  7.0000  ...        Good            809.98   \n",
       "3                  4.0000  ...        Good            809.98   \n",
       "4                 30.9254  ...        Good            809.98   \n",
       "\n",
       "  Credit_Utilization_Ratio  Credit_History_Age  Payment_of_Min_Amount  \\\n",
       "0                26.822620            265.0000                     No   \n",
       "1                31.944960            221.1933                     No   \n",
       "2                28.609352            267.0000                     No   \n",
       "3                31.377862            268.0000                     No   \n",
       "4                24.797347            269.0000                     No   \n",
       "\n",
       "   Total_EMI_per_month Amount_invested_monthly  \\\n",
       "0            49.574949               80.415295   \n",
       "1            49.574949              118.280222   \n",
       "2            49.574949               81.699521   \n",
       "3            49.574949              199.458074   \n",
       "4            49.574949               41.420153   \n",
       "\n",
       "                  Payment_Behaviour  Monthly_Balance Credit_Score  \n",
       "0   High_spent_Small_value_payments       312.494089         True  \n",
       "1    Low_spent_Large_value_payments       284.629162         True  \n",
       "2   Low_spent_Medium_value_payments       331.209863         True  \n",
       "3    Low_spent_Small_value_payments       223.451310         True  \n",
       "4  High_spent_Medium_value_payments       341.489231         True  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_score_df = pd.read_csv(\"~/Documents/datasets/transformed_credit_score.csv\")\n",
    "\n",
    "credit_score_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9091e5f5-d75d-4174-a71a-92a4b943c0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Выделим целевую переменную \n",
    "X = credit_score_df.drop(columns = ['Credit_Score'])\n",
    "y = credit_score_df['Credit_Score']\n",
    "\n",
    "X = pd.get_dummies(X, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1642890f-8d45-41de-aa46-7b871d0f6792",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Разделим выборку на обучающую и тестовую\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify=y, shuffle=True, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2c06e4b-1344-4c93-bb92-60d46cca99fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((79992, 43), (19999, 43))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e570e97-3106-43de-a599-850b78321ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Нормализуем данные с помощью StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "X_train_std = scaler.transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20205db2-05ee-4247-93ba-fd68e90c5025",
   "metadata": {},
   "source": [
    "Построим `baseline` модель в виде `LogisticRegression`, подберём оптимальные гипперпараметры, после чего будем сравнивать улучшилась ли метрика `AUC-ROC` при построении более сложных моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99e9cba1-4515-4785-934b-be9ca8620549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC ROC score for logistic regression on train: 0.663\n",
      "AUC ROC score for logistic regression on test: 0.657\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "logistic_model.fit(X_train_std, y_train)\n",
    "\n",
    "print(f\"AUC ROC score for logistic regression on train: {roc_auc_score(y_train, logistic_model.predict(X_train_std)):.3f}\")\n",
    "print(f\"AUC ROC score for logistic regression on test: {roc_auc_score(y_test, logistic_model.predict(X_test_std)):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdaa6d42-33b5-4006-a08e-02424f4d8b29",
   "metadata": {},
   "source": [
    "Модель уже неплохо разделяет выборку, `AUC-ROC` на тестовых данных сопоставим с значением на тренировочной, значит модель не переобучается на наших данных.\n",
    "\n",
    "Теперь подберем оптимальне гипперпараметры для логистической регресси с помощью `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f05fa656-8d3d-4b60-ab98-3e7547e11e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best Parameters: {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best Score: 0.785\n",
      "Test Score: 0.785\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear', 'lbfgs']\n",
    "}\n",
    "\n",
    "grid_search1 = GridSearchCV(estimator=logistic_model, \n",
    "                            param_grid=param_grid, \n",
    "                            cv=5, \n",
    "                            scoring='roc_auc',\n",
    "                            verbose = 1)\n",
    "\n",
    "grid_search1.fit(X_train_std, y_train)\n",
    "\n",
    "print(f\"Best Parameters: {grid_search1.best_params_}\")\n",
    "print(f\"Best Score: {grid_search1.best_score_:.3f}\")\n",
    "print(f\"Test Score: {grid_search1.score(X_test_std, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933c2dbc-0854-43b9-b8e4-7ef07edec502",
   "metadata": {},
   "source": [
    "Зафиксируем лучшие гипперпараметры для `LogisticRegression`, посмотрим как изменился `AUC-ROC` на тестовой выборке, также выведем `classification_report`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "378d1ecf-3775-4dff-b404-fe4e4511b998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC ROC score for logistic regression on test: 0.658\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.64      0.41      0.50      5800\n",
      "        True       0.79      0.91      0.84     14199\n",
      "\n",
      "    accuracy                           0.76     19999\n",
      "   macro avg       0.71      0.66      0.67     19999\n",
      "weighted avg       0.75      0.76      0.74     19999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "best_logistic_model = LogisticRegression(C = 0.1, penalty = 'l1', solver = 'liblinear')\n",
    "\n",
    "best_logistic_model.fit(X_train_std, y_train)\n",
    "\n",
    "print(f\"AUC ROC score for logistic regression on test: {roc_auc_score(y_test, best_logistic_model.predict(X_test_std)):.3f}\")\n",
    "print(f\"Classification report:\\n {classification_report(y_test, best_logistic_model.predict(X_test_std))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52191ac9-7d25-483b-823f-dcbc22bd8514",
   "metadata": {},
   "source": [
    "Как мы видем `AUC-ROC` практически не изменился, подбор параметров не сильно повлиял на модель. Проведем кросс-валидацию для нашей `baseline` модели, далее будем пытаться улучшать это значение с помощью других моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e50eb26c-8c31-476e-b79e-57b3940d4fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUC-ROC with cross validation on logistic regression: 0.784\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "pipeline = make_pipeline(StandardScaler(), \n",
    "                         best_logistic_model)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(pipeline, X, y, cv=kf, scoring='roc_auc')\n",
    "\n",
    "print(f\"Mean AUC-ROC with cross validation on logistic regression: {np.mean(scores):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357ae580-1d43-4a71-89e7-29da5c2eb55c",
   "metadata": {},
   "source": [
    "После того как мы получили среднее значение `AUC-ROC` для нашей `baseline` модели, будем пытаться улучшить данное значение с помощью других моделей: `RandomForestClassifier`, `KNeighborsClassifier`, `XGBClassifier`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8262a5-c792-4ad0-9d3f-32e4445161fc",
   "metadata": {},
   "source": [
    "Обучим модель `RandomForestClassifier`, подберем гипперпараметры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7492de6a-b70b-41e9-b6e9-54eed30e6776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC ROC score for random forest on train: 1.000\n",
      "AUC ROC score for random forest on test: 0.843\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "rf_model.fit(X_train_std, y_train)\n",
    "\n",
    "print(f\"AUC ROC score for random forest on train: {roc_auc_score(y_train, rf_model.predict(X_train_std)):.3f}\")\n",
    "print(f\"AUC ROC score for random forest on test: {roc_auc_score(y_test, rf_model.predict(X_test_std)):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f84e8b-4a59-4e7d-81b6-6b1294273402",
   "metadata": {},
   "source": [
    "Теперь подберем гипперпараметры для случайного леса с помощью `RandomizedSearch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26b5c3d7-b770-4c03-a2e8-06f9dabe3b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "Best Parameters: {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 50}\n",
      "Best Score: 0.915\n",
      "Test Score: 0.930\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 200], \n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth': [5, 10, 20, 30, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rand_search1 = RandomizedSearchCV(estimator=rf_model, \n",
    "                                  param_distributions=param_dist, \n",
    "                                  cv=3,\n",
    "                                  n_iter=30,\n",
    "                                  scoring='roc_auc', \n",
    "                                  verbose = 1,\n",
    "                                  random_state = 42)\n",
    "\n",
    "rand_search1.fit(X_train_std, y_train)\n",
    "\n",
    "print(f\"Best Parameters: {rand_search1.best_params_}\")\n",
    "print(f\"Best Score: {rand_search1.best_score_:.3f}\")\n",
    "print(f\"Test Score: {rand_search1.score(X_test_std, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4cd9cca0-a42e-48c9-a520-76db0d162eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC ROC score for best random forest on test: 0.83\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.79      0.75      0.77      5800\n",
      "        True       0.90      0.92      0.91     14199\n",
      "\n",
      "    accuracy                           0.87     19999\n",
      "   macro avg       0.85      0.83      0.84     19999\n",
      "weighted avg       0.87      0.87      0.87     19999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "best_rf_model = RandomForestClassifier(n_estimators = 200, \n",
    "                                       min_samples_split = 2, \n",
    "                                       min_samples_leaf = 1, \n",
    "                                       max_features = 'log2', \n",
    "                                       max_depth = 30)\n",
    "\n",
    "best_rf_model.fit(X_train_std, y_train)\n",
    "\n",
    "print(f\"AUC ROC score for best random forest on test: {roc_auc_score(y_test, best_rf_model.predict(X_test_std)):.2f}\")\n",
    "print(f\"Classification report:\\n {classification_report(y_test, best_rf_model.predict(X_test_std))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e00430-6fa0-404c-9796-88c1a5907dbd",
   "metadata": {},
   "source": [
    "Посчитаем среднее значение метрики на кросс-валидации для случайного леса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c6eca6f-52f7-4f84-b718-99446bfec0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUC-ROC with cross validation on random forest: 0.926\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "pipeline = make_pipeline(StandardScaler(), \n",
    "                         best_rf_model)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(pipeline, X, y, cv=kf, scoring='roc_auc')\n",
    "\n",
    "print(f\"Mean AUC-ROC with cross validation on random forest: {np.mean(scores):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8153ec-251a-4b96-91b7-8e7470f0f378",
   "metadata": {},
   "source": [
    "Обучим модель `KNeighborsClassifier`, подберем гипперпараметры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "536f886e-2737-4bb0-acb8-77feef1835c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC ROC score for KNN on train: 0.774\n",
      "AUC ROC score for KNN on test: 0.690\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors = 5)\n",
    "\n",
    "knn_model.fit(X_train_std, y_train)\n",
    "\n",
    "print(f\"AUC ROC score for KNN on train: {roc_auc_score(y_train, knn_model.predict(X_train_std)):.3f}\")\n",
    "print(f\"AUC ROC score for KNN on test: {roc_auc_score(y_test, knn_model.predict(X_test_std)):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08149ddb-e0c0-49e6-b1b4-2527b87e8664",
   "metadata": {},
   "source": [
    "Теперь подберем гипперпараметры для `KNN` с помощью `RandomizedSearch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "085da812-77b2-436a-be6e-1170aaa70770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Best Parameters: {'weights': 'distance', 'n_neighbors': 9, 'metric': 'manhattan'}\n",
      "Best Score: 0.809\n",
      "Test Score: 0.826\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "}\n",
    "\n",
    "rand_search2 = RandomizedSearchCV(estimator=knn_model, \n",
    "                                  param_distributions=param_dist, \n",
    "                                  cv=3,\n",
    "                                  n_iter=20,\n",
    "                                  scoring='roc_auc', \n",
    "                                  verbose = 1,\n",
    "                                  random_state = 42)\n",
    "\n",
    "\n",
    "rand_search2.fit(X_train_std, y_train)\n",
    "\n",
    "print(f\"Best Parameters: {rand_search2.best_params_}\")\n",
    "print(f\"Best Score: {rand_search2.best_score_:.3f}\")\n",
    "print(f\"Test Score: {rand_search2.score(X_test_std, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a8c9ccd7-ee89-41b9-80ad-036a3bd3d50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC ROC score for best KNN on test: 0.720\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.70      0.53      0.61      5800\n",
      "        True       0.83      0.91      0.86     14199\n",
      "\n",
      "    accuracy                           0.80     19999\n",
      "   macro avg       0.76      0.72      0.74     19999\n",
      "weighted avg       0.79      0.80      0.79     19999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "best_knn_model = KNeighborsClassifier(weights = 'distance', \n",
    "                                      n_neighbors = 9, \n",
    "                                      metric = 'manhattan')\n",
    "\n",
    "best_knn_model.fit(X_train_std, y_train)\n",
    "\n",
    "print(f\"AUC ROC score for best KNN on test: {roc_auc_score(y_test, best_knn_model.predict(X_test_std)):.3f}\")\n",
    "print(f\"Classification report:\\n {classification_report(y_test, best_knn_model.predict(X_test_std))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e89a79-aec7-48d0-a9c8-836072276c04",
   "metadata": {},
   "source": [
    "Посчитаем среднее значение метрики на кросс-валидации для `KNN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b4c68b6-826c-4936-8344-4bad56aaaa37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUC-ROC with cross validation on KNN: 0.820\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "pipeline = make_pipeline(StandardScaler(), \n",
    "                         best_knn_model)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(pipeline, X, y, cv=kf, scoring='roc_auc')\n",
    "\n",
    "print(f\"Mean AUC-ROC with cross validation on KNN: {np.mean(scores):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e587fca-74fb-410b-8f0f-79f24d02a90d",
   "metadata": {},
   "source": [
    "Теперь обучим `XGBClassifier` из библиотеки `xgboost`, попробуем подобрать гипперапараметры так, чтобы обогнать модель случайного леса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e2ebdb0f-aa00-4493-bbe2-88ad2ab67688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC ROC score for gradient boosting on train: 0.86\n",
      "F1 score for gradient boosting on train: 0.92\n",
      "\n",
      "AUC ROC score for gradient boosting on test: 0.81\n",
      "F1 score for gradient boosting on test: 0.90\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "gb_model = XGBClassifier()\n",
    "\n",
    "gb_model.fit(X_train_std, y_train)\n",
    "\n",
    "print(f\"AUC ROC score for gradient boosting on train: {roc_auc_score(y_train, gb_model.predict(X_train_std)):.2f}\")\n",
    "print(f\"F1 score for gradient boosting on train: {f1_score(y_train, gb_model.predict(X_train_std)):.2f}\\n\")\n",
    "print(f\"AUC ROC score for gradient boosting on test: {roc_auc_score(y_test, gb_model.predict(X_test_std)):.2f}\")\n",
    "print(f\"F1 score for gradient boosting on test: {f1_score(y_test, gb_model.predict(X_test_std)):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0d5880bb-38b8-434f-8be8-87b775c38b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 150 candidates, totalling 750 fits\n",
      "Best Parameters: {'colsample_bytree': 0.6066351315711425, 'gamma': 0.2560465291496405, 'learning_rate': 0.075683774807402, 'max_depth': 10, 'min_child_weight': 7, 'n_estimators': 869, 'reg_alpha': 0.940523264489604, 'reg_lambda': 1.3975720210875222, 'subsample': 0.8071005402109921}\n",
      "Best Score: 0.926\n",
      "Test Score: 0.936\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "gb_param_dist = {\n",
    "    'learning_rate': uniform(0.01, 0.29),\n",
    "    'max_depth': randint(3, 11),\n",
    "    'min_child_weight': randint(1, 11),\n",
    "    'gamma': uniform(0, 0.5),\n",
    "    'subsample': uniform(0.6, 0.4),\n",
    "    'colsample_bytree': uniform(0.6, 0.4),\n",
    "    'reg_alpha': uniform(0, 1),\n",
    "    'reg_lambda': uniform(1, 1),\n",
    "    'n_estimators': randint(50, 1001)\n",
    "    }\n",
    "\n",
    "rand_search3 = RandomizedSearchCV(estimator=gb_model, \n",
    "                                  param_distributions=gb_param_dist, \n",
    "                                  cv=5,\n",
    "                                  n_iter=150,\n",
    "                                  scoring='roc_auc', \n",
    "                                  verbose = 1,\n",
    "                                  random_state = 42)\n",
    "\n",
    "\n",
    "rand_search3.fit(X_train_std, y_train)\n",
    "\n",
    "print(f\"Best Parameters: {rand_search3.best_params_}\")\n",
    "print(f\"Best Score: {rand_search3.best_score_:.3f}\")\n",
    "print(f\"Test Score: {rand_search3.score(X_test_std, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "923f6033-9b9d-49f4-8f35-85e100b0071f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC ROC score for gradient boosting on test: 0.848\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.80      0.77      0.79      5800\n",
      "        True       0.91      0.92      0.91     14199\n",
      "\n",
      "    accuracy                           0.88     19999\n",
      "   macro avg       0.85      0.85      0.85     19999\n",
      "weighted avg       0.88      0.88      0.88     19999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "best_gb_model = XGBClassifier(colsample_bytree = 0.606, \n",
    "                                     gamma = 0.256, \n",
    "                                     learning_rate = 0.075,\n",
    "                                     max_depth = 10,\n",
    "                                     min_child_weight = 7,\n",
    "                                     n_estimators = 869,\n",
    "                                     reg_alpha = 0.94,\n",
    "                                     reg_lambda = 1.397,\n",
    "                                     subsample = 0.807)\n",
    "\n",
    "best_gb_model.fit(X_train_std, y_train)\n",
    "\n",
    "print(f\"AUC ROC score for gradient boosting on test: {roc_auc_score(y_test, best_gb_model.predict(X_test_std)):.3f}\")\n",
    "print(f\"Classification report:\\n {classification_report(y_test, best_gb_model.predict(X_test_std))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18025c78-f76c-424c-9af7-245e23ebe733",
   "metadata": {},
   "source": [
    "Теперь найдем среднее значение `AUC-ROC` для модели градиентного бустинга на кросс-валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2e904c1d-d737-4167-9aee-3166e8e42d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUC-ROC with cross validation on gradient boosting: 0.933\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "pipeline = make_pipeline(StandardScaler(), best_gb_model)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(pipeline, X, y, cv=kf, scoring='roc_auc')\n",
    "\n",
    "print(f\"Mean AUC-ROC with cross validation on gradient boosting: {np.mean(scores):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24b3b74-f1ea-44ac-86cf-887bfbc44388",
   "metadata": {},
   "source": [
    "В качестве baseline модели для решения задачи классификации мы используем `Logistic regression`. После чего попробуем использовать `KNN`, `Random forest`, `GBM` из библиотеки `xgboost`. Подберем гипперпараметры для данных моделей. Также сделаем отбор признаков в датасете, посмотрим как улучшится качество. Также можно выделить признаки с помощью `PCA`. Будем пытаться улучшить модели по метрике `AUC-ROC`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c1c7dbe3-df88-48d6-ab80-44da6e07282d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cc148ceb-ba58-4d7a-8c33-453986811d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Annual_Income</th>\n",
       "      <th>Monthly_Inhand_Salary</th>\n",
       "      <th>Num_Bank_Accounts</th>\n",
       "      <th>Num_Credit_Card</th>\n",
       "      <th>Interest_Rate</th>\n",
       "      <th>Num_of_Loan</th>\n",
       "      <th>Delay_from_due_date</th>\n",
       "      <th>Num_of_Delayed_Payment</th>\n",
       "      <th>...</th>\n",
       "      <th>Credit_Mix</th>\n",
       "      <th>Outstanding_Debt</th>\n",
       "      <th>Credit_Utilization_Ratio</th>\n",
       "      <th>Credit_History_Age</th>\n",
       "      <th>Payment_of_Min_Amount</th>\n",
       "      <th>Total_EMI_per_month</th>\n",
       "      <th>Amount_invested_monthly</th>\n",
       "      <th>Payment_Behaviour</th>\n",
       "      <th>Monthly_Balance</th>\n",
       "      <th>Credit_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.0</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>1824.843333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>_</td>\n",
       "      <td>809.98</td>\n",
       "      <td>26.822620</td>\n",
       "      <td>265.0000</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>80.415295</td>\n",
       "      <td>High_spent_Small_value_payments</td>\n",
       "      <td>312.494089</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.0</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>4194.150202</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>30.9254</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>809.98</td>\n",
       "      <td>31.944960</td>\n",
       "      <td>221.1933</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>118.280222</td>\n",
       "      <td>Low_spent_Large_value_payments</td>\n",
       "      <td>284.629162</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.0</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>4194.150202</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>809.98</td>\n",
       "      <td>28.609352</td>\n",
       "      <td>267.0000</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>81.699521</td>\n",
       "      <td>Low_spent_Medium_value_payments</td>\n",
       "      <td>331.209863</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.0</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>4194.150202</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>809.98</td>\n",
       "      <td>31.377862</td>\n",
       "      <td>268.0000</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>199.458074</td>\n",
       "      <td>Low_spent_Small_value_payments</td>\n",
       "      <td>223.451310</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.0</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>1824.843333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>30.9254</td>\n",
       "      <td>...</td>\n",
       "      <td>Good</td>\n",
       "      <td>809.98</td>\n",
       "      <td>24.797347</td>\n",
       "      <td>269.0000</td>\n",
       "      <td>No</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>41.420153</td>\n",
       "      <td>High_spent_Medium_value_payments</td>\n",
       "      <td>341.489231</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age Occupation  Annual_Income  Monthly_Inhand_Salary  Num_Bank_Accounts  \\\n",
       "0  23.0  Scientist       19114.12            1824.843333                3.0   \n",
       "1  23.0  Scientist       19114.12            4194.150202                3.0   \n",
       "2  33.0  Scientist       19114.12            4194.150202                3.0   \n",
       "3  23.0  Scientist       19114.12            4194.150202                3.0   \n",
       "4  23.0  Scientist       19114.12            1824.843333                3.0   \n",
       "\n",
       "   Num_Credit_Card  Interest_Rate  Num_of_Loan  Delay_from_due_date  \\\n",
       "0              4.0            3.0          4.0                  3.0   \n",
       "1              4.0            3.0          4.0                 -1.0   \n",
       "2              4.0            3.0          4.0                  3.0   \n",
       "3              4.0            3.0          4.0                  5.0   \n",
       "4              4.0            3.0          4.0                  6.0   \n",
       "\n",
       "   Num_of_Delayed_Payment  ...  Credit_Mix  Outstanding_Debt  \\\n",
       "0                  7.0000  ...           _            809.98   \n",
       "1                 30.9254  ...        Good            809.98   \n",
       "2                  7.0000  ...        Good            809.98   \n",
       "3                  4.0000  ...        Good            809.98   \n",
       "4                 30.9254  ...        Good            809.98   \n",
       "\n",
       "  Credit_Utilization_Ratio  Credit_History_Age  Payment_of_Min_Amount  \\\n",
       "0                26.822620            265.0000                     No   \n",
       "1                31.944960            221.1933                     No   \n",
       "2                28.609352            267.0000                     No   \n",
       "3                31.377862            268.0000                     No   \n",
       "4                24.797347            269.0000                     No   \n",
       "\n",
       "   Total_EMI_per_month Amount_invested_monthly  \\\n",
       "0            49.574949               80.415295   \n",
       "1            49.574949              118.280222   \n",
       "2            49.574949               81.699521   \n",
       "3            49.574949              199.458074   \n",
       "4            49.574949               41.420153   \n",
       "\n",
       "                  Payment_Behaviour  Monthly_Balance Credit_Score  \n",
       "0   High_spent_Small_value_payments       312.494089         True  \n",
       "1    Low_spent_Large_value_payments       284.629162         True  \n",
       "2   Low_spent_Medium_value_payments       331.209863         True  \n",
       "3    Low_spent_Small_value_payments       223.451310         True  \n",
       "4  High_spent_Medium_value_payments       341.489231         True  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_score_df = pd.read_csv(\"~/Documents/datasets/transformed_credit_score.csv\")\n",
    "\n",
    "credit_score_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6067ae05-6681-479a-8da3-0c49fc406647",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Выделим целевую переменную \n",
    "X = credit_score_df.drop(columns = ['Credit_Score'])\n",
    "y = credit_score_df['Credit_Score']\n",
    "\n",
    "X = pd.get_dummies(X, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "63d3fc6c-dbef-4d03-a3f0-6b0a656c7f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Разделим выборку на обучающую и тестовую\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify=y,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9cb87c05-ef7c-4c77-a185-6a7d52da3ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((79992, 43), (19999, 43))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7498538a-5973-472f-b9b1-17cc41a80ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Нормализуем данные с помощью StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "X_train_std = scaler.transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae45a4ad-efab-40ae-9475-b2240db195a8",
   "metadata": {},
   "source": [
    "Построим `baseline` в виде `LogisticRegression`, подберём гипперпараметры, затем будем пытаться улучшить рекорд  с помощью других моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8dfca2c8-2a8d-4447-88e4-f3c9471cee65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC ROC score for logistic regression on train: 0.66\n",
      "F1 score for logistic regression on train: 0.84\n",
      "\n",
      "AUC ROC score for logistic regression on test: 0.66\n",
      "F1 score for logistic regression on test: 0.84\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, classification_report, f1_score\n",
    "\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "logistic_model.fit(X_train_std, y_train)\n",
    "\n",
    "print(f\"AUC ROC score for logistic regression on train: {roc_auc_score(y_train, logistic_model.predict(X_train_std)):.2f}\")\n",
    "print(f\"F1 score for logistic regression on train: {f1_score(y_train, logistic_model.predict(X_train_std)):.2f}\\n\")\n",
    "print(f\"AUC ROC score for logistic regression on test: {roc_auc_score(y_test, logistic_model.predict(X_test_std)):.2f}\")\n",
    "print(f\"F1 score for logistic regression on test: {f1_score(y_test, logistic_model.predict(X_test_std)):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891fb0d2-c52f-4ac8-9614-0c898637f091",
   "metadata": {},
   "source": [
    "Подберем гипперпараметры с помощью `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5be2f232-17c4-4826-8d63-f4d487b05715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best Score: 0.7845962630356117\n",
      "Test Score: 0.7848786339980232\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear', 'lbfgs']\n",
    "}\n",
    "\n",
    "grid_search1 = GridSearchCV(estimator=logistic_model, param_grid=param_grid, cv=5, scoring='roc_auc')\n",
    "\n",
    "grid_search1.fit(X_train_std, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search1.best_params_)\n",
    "print(\"Best Score:\", grid_search1.best_score_)\n",
    "print(\"Test Score:\", grid_search1.score(X_test_std, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d95a1b-079e-4751-82f9-e21777e9b62a",
   "metadata": {},
   "source": [
    "Подберем гипперпараметры более масштабно с помощью `RandomizedSearch`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b23e28-f489-4575-a496-26114bab564e",
   "metadata": {},
   "source": [
    "Метрики практически не изменились, зафиксируем лучшие параметры для `LogisticRegression`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a1dc9711-a5bd-4101-ba52-414df51ef145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC ROC score for logistic regression on test: 0.66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.64      0.41      0.50      5800\n",
      "        True       0.79      0.91      0.84     14199\n",
      "\n",
      "    accuracy                           0.76     19999\n",
      "   macro avg       0.71      0.66      0.67     19999\n",
      "weighted avg       0.75      0.76      0.74     19999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, classification_report, f1_score\n",
    "\n",
    "best_logistic_model = LogisticRegression(C = 0.1, penalty = 'l1', solver = 'liblinear')\n",
    "\n",
    "best_logistic_model.fit(X_train_std, y_train)\n",
    "\n",
    "print(f\"AUC ROC score for logistic regression on test: {roc_auc_score(y_test, best_logistic_model.predict(X_test_std)):.2f}\")\n",
    "print(classification_report(y_test, best_logistic_model.predict(X_test_std)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2467ee9d-b532-4467-b3d4-27424e558ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUC-ROC with cross validation on logistic regression: 0.7843568584948808\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "pipeline = make_pipeline(StandardScaler(), LogisticRegression(C=0.1, penalty='l1', solver='liblinear'))\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(pipeline, X, y, cv=kf, scoring='roc_auc')\n",
    "\n",
    "print(\"Mean AUC-ROC with cross validation on logistic regression:\", np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ce3f79-9bc4-4c9c-b210-d9af295a0276",
   "metadata": {},
   "source": [
    "Теперь обучим модель `RandomForestClassifier`, подберем гипперпараметры и посмотрим как улучшится `AUC_ROC`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9363ae22-7843-4e02-95c9-720bf398182a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC ROC score for random forest on train: 1.00\n",
      "F1 score for random forest on train: 1.00\n",
      "\n",
      "AUC ROC score for random forest on test: 0.84\n",
      "F1 score for random forest on test: 0.91\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "rf_model.fit(X_train_std, y_train)\n",
    "\n",
    "print(f\"AUC ROC score for random forest on train: {roc_auc_score(y_train, rf_model.predict(X_train_std)):.2f}\")\n",
    "print(f\"F1 score for random forest on train: {f1_score(y_train, rf_model.predict(X_train_std)):.2f}\\n\")\n",
    "print(f\"AUC ROC score for random forest on test: {roc_auc_score(y_test, rf_model.predict(X_test_std)):.2f}\")\n",
    "print(f\"F1 score for random forest on test: {f1_score(y_test, rf_model.predict(X_test_std)):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c469db0-510d-42a3-82a2-569469ebeeb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "[CV 1/3] END max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.838 total time=   3.2s\n",
      "[CV 2/3] END max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.838 total time=   3.2s\n",
      "[CV 3/3] END max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.843 total time=   3.1s\n",
      "[CV 1/3] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.905 total time=  18.8s\n",
      "[CV 2/3] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.908 total time=  19.0s\n",
      "[CV 3/3] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.907 total time=  19.2s\n",
      "[CV 1/3] END max_depth=50, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.907 total time=  10.2s\n",
      "[CV 2/3] END max_depth=50, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.908 total time=  10.3s\n",
      "[CV 3/3] END max_depth=50, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.909 total time=  10.2s\n",
      "[CV 1/3] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.844 total time=   1.8s\n",
      "[CV 2/3] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.842 total time=   1.8s\n",
      "[CV 3/3] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.845 total time=   1.8s\n",
      "[CV 1/3] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.838 total time=   1.8s\n",
      "[CV 2/3] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.839 total time=   1.8s\n",
      "[CV 3/3] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.845 total time=   1.8s\n",
      "[CV 1/3] END max_depth=5, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.837 total time=   6.3s\n",
      "[CV 2/3] END max_depth=5, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.838 total time=   6.4s\n",
      "[CV 3/3] END max_depth=5, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.841 total time=   6.3s\n",
      "[CV 1/3] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.869 total time=  11.3s\n",
      "[CV 2/3] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.871 total time=  11.3s\n",
      "[CV 3/3] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.872 total time=  11.2s\n",
      "[CV 1/3] END max_depth=50, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/3] END max_depth=50, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/3] END max_depth=50, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/3] END max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.909 total time=  12.1s\n",
      "[CV 2/3] END max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.913 total time=  11.9s\n",
      "[CV 3/3] END max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.912 total time=  11.9s\n",
      "[CV 1/3] END max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 2/3] END max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 3/3] END max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=nan total time=   0.0s\n",
      "[CV 1/3] END max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.911 total time=  24.1s\n",
      "[CV 2/3] END max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.914 total time=  23.4s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 200], \n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth': [5, 10, 20, 30, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rand_search1 = RandomizedSearchCV(estimator=rf_model, \n",
    "                                  param_distributions=param_dist, \n",
    "                                  cv=3,\n",
    "                                  n_iter=30,\n",
    "                                  scoring='roc_auc', \n",
    "                                  verbose = 3,\n",
    "                                  random_state = 42)\n",
    "\n",
    "rand_search1.fit(X_train_std, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", rand_search1.best_params_)\n",
    "print(\"Best Score:\", rand_search1.best_score_)\n",
    "print(\"Test Score:\", rand_search1.score(X_test_std, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b2461e-0908-4a9e-a3fa-a20112e6b7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf_model = RandomForestClassifier(n_estimators = 200, \n",
    "                                       min_samples_split = 2, \n",
    "                                       min_samples_leaf = 1, \n",
    "                                       max_features = 'log2', \n",
    "                                       max_depth = 30)\n",
    "\n",
    "best_rf_model.fit(X_train_std, y_train)\n",
    "\n",
    "print(f\"AUC ROC score for best random forest on test: {roc_auc_score(y_test, best_rf_model.predict(X_test_std)):.2f}\")\n",
    "print(\"Classification report:\\n\", classification_report(y_test, best_rf_model.predict(X_test_std)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f84173-6730-45b3-a9a5-9a57003df1e0",
   "metadata": {},
   "source": [
    "Посчитаем среднее значение метрики на кросс-валидации для `KNN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66eb3a33-348b-4229-a384-13ebf0e65349",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "pipeline = make_pipeline(StandardScaler(), RandomForestClassifier(n_estimators = 200, \n",
    "                                       min_samples_split = 2, \n",
    "                                       min_samples_leaf = 1, \n",
    "                                       max_features = 'log2', \n",
    "                                       max_depth = 30))\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(pipeline, X, y, cv=kf, scoring='roc_auc')\n",
    "\n",
    "print(\"Mean AUC-ROC with cross validation on fandom forest:\", np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2f8246-0efd-46ce-ad81-6f9411ceea2c",
   "metadata": {},
   "source": [
    "Теперь обучим модель `KNeighborsClassifier`, подберем гипперпараметры и посмотрим как улучшится `AUC_ROC`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49f264a-d5cd-4280-9613-3af2eda042be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors = 5)\n",
    "\n",
    "knn_model.fit(X_train_std, y_train)\n",
    "\n",
    "print(f\"AUC ROC score for k-nearest neighbors on train: {roc_auc_score(y_train, knn_model.predict(X_train_std)):.2f}\")\n",
    "print(f\"F1 score for k-nearest neighbors on train: {f1_score(y_train, knn_model.predict(X_train_std)):.2f}\\n\")\n",
    "print(f\"AUC ROC score for k-nearest neighbors on test: {roc_auc_score(y_test, knn_model.predict(X_test_std)):.2f}\")\n",
    "print(f\"F1 score for k-nearest neighbors on test: {f1_score(y_test, knn_model.predict(X_test_std)):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2a5a36-fde9-436e-8435-062ddaff88be",
   "metadata": {},
   "source": [
    "Применим `RandomizedSearchCV`для поиска гипперпараметров для `KNN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3fac91-3d36-4d5a-b2c1-d623664f649d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_dist = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "}\n",
    "\n",
    "rand_search2 = RandomizedSearchCV(estimator=knn_model, \n",
    "                                  param_distributions=param_dist, \n",
    "                                  cv=3,\n",
    "                                  n_iter=20,\n",
    "                                  scoring='roc_auc', \n",
    "                                  verbose = 3,\n",
    "                                  random_state = 42)\n",
    "\n",
    "\n",
    "rand_search2.fit(X_train_std, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", rand_search2.best_params_)\n",
    "print(\"Best Score:\", rand_search2.best_score_)\n",
    "print(\"Test Score:\", rand_search2.score(X_test_std, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e139d7-0f4c-4ddb-b5c5-1ff0fd7f8d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "best_knn_model = KNeighborsClassifier(weights = 'distance', n_neighbors = 9, metric = 'manhattan')\n",
    "\n",
    "best_knn_model.fit(X_train_std, y_train)\n",
    "\n",
    "print(f\"AUC ROC score for k-nearest neighbors on train: {roc_auc_score(y_train, best_knn_model.predict(X_train_std)):.2f}\")\n",
    "print(f\"F1 score for k-nearest neighbors on train: {f1_score(y_train, best_knn_model.predict(X_train_std)):.2f}\\n\")\n",
    "print(f\"AUC ROC score for k-nearest neighbors on test: {roc_auc_score(y_test, best_knn_model.predict(X_test_std)):.2f}\")\n",
    "print(f\"F1 score for k-nearest neighbors on test: {f1_score(y_test, best_knn_model.predict(X_test_std)):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b673c8-9a6f-4fdf-a264-4805c1057402",
   "metadata": {},
   "source": [
    "Теперь обучим `XGBClassifier` из библиотеки `xgboost`, попробуем подобрать гипперапараметры так, чтобы обогнать модель случайного леса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39495e2-c68d-40d1-b922-25f1a7f83b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "gb_model = XGBClassifier()\n",
    "\n",
    "gb_model.fit(X_train_std, y_train)\n",
    "\n",
    "print(f\"AUC ROC score for gradient boosting on train: {roc_auc_score(y_train, gb_model.predict(X_train_std)):.2f}\")\n",
    "print(f\"F1 score for gradient boosting on train: {f1_score(y_train, gb_model.predict(X_train_std)):.2f}\\n\")\n",
    "print(f\"AUC ROC score for gradient boosting on test: {roc_auc_score(y_test, gb_model.predict(X_test_std)):.2f}\")\n",
    "print(f\"F1 score for gradient boosting on test: {f1_score(y_test, gb_model.predict(X_test_std)):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fa646a-bf92-46a0-8e94-a1718a774eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "gb_param_dist = {\n",
    "    'learning_rate': uniform(0.01, 0.29),\n",
    "    'max_depth': randint(3, 11),\n",
    "    'min_child_weight': randint(1, 11),\n",
    "    'gamma': uniform(0, 0.5),\n",
    "    'subsample': uniform(0.6, 0.4),\n",
    "    'colsample_bytree': uniform(0.6, 0.4),\n",
    "    'reg_alpha': uniform(0, 1),\n",
    "    'reg_lambda': uniform(1, 1),\n",
    "    'n_estimators': randint(50, 1001)\n",
    "    }\n",
    "\n",
    "rand_search3 = RandomizedSearchCV(estimator=gb_model, \n",
    "                                  param_distributions=gb_param_dist, \n",
    "                                  cv=5,\n",
    "                                  n_iter=150,\n",
    "                                  scoring='roc_auc', \n",
    "                                  verbose = 3,\n",
    "                                  random_state = 42)\n",
    "\n",
    "\n",
    "rand_search3.fit(X_train_std, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", rand_search3.best_params_)\n",
    "print(\"Best Score:\", rand_search3.best_score_)\n",
    "print(\"Test Score:\", rand_search3.score(X_test_std, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880f9be1-5339-4711-9a06-0695321914cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "best_gb_model = XGBClassifier(colsample_bytree = 0.606, \n",
    "                                     gamma = 0.256, \n",
    "                                     learning_rate = 0.075,\n",
    "                                     max_depth = 10,\n",
    "                                     min_child_weight = 7,\n",
    "                                     n_estimators = 869,\n",
    "                                     reg_alpha = 0.94,\n",
    "                                     reg_lambda = 1.397,\n",
    "                                     subsample = 0.807)\n",
    "\n",
    "best_gb_model.fit(X_train_std, y_train)\n",
    "\n",
    "print(f\"AUC ROC score for gradient boosting on test: {roc_auc_score(y_test, best_gb_model.predict(X_test_std)):.3f}\")\n",
    "print(f\"Classification report:\\n {classification_report(y_test, best_gb_model.predict(X_test_std))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07b6960-5623-4007-8784-fb5b25952f84",
   "metadata": {},
   "source": [
    "Теперь найдем среднее значение `AUC-ROC` для модели градиентного бустинга на кросс-валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3816b52-2d5c-404b-81c4-67172320f4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "pipeline = make_pipeline(StandardScaler(), best_gb_model)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(pipeline, X, y, cv=kf, scoring='roc_auc')\n",
    "\n",
    "print(f\"Mean AUC-ROC with cross validation on gradient boosting: {np.mean(scores):.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
